{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_modelo_dnn_subclassing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bGOMghMO79i-edx4rrQ6hNT2JFY8qpr1",
      "authorship_tag": "ABX9TyOarVsADk8oMfeRyMQYp7J4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernandofsilva/LSTM_Option_Pricing/blob/main/notebooks/03_modelo_dnn_subclassing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4s1_juM4i29"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd5nfmTLtHpS",
        "cellView": "form"
      },
      "source": [
        "#@title Carregando as bibliotecas base\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "\n",
        "seaborn.set_style('whitegrid')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOP6RdSctQxa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "cellView": "form",
        "outputId": "67a45f6e-ad41-4df0-95e4-608cb860d5b7"
      },
      "source": [
        "#@title Carregando os dados\n",
        "data = pd.read_csv(f'/content/drive/My Drive/Mestrado/data/dados_treino_teste.csv.gz', compression='gzip', index_col=0)\n",
        "data.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>codigo</th>\n",
              "      <th>mercado</th>\n",
              "      <th>preco_opcao</th>\n",
              "      <th>preco_exercicio</th>\n",
              "      <th>data_vencimento</th>\n",
              "      <th>T</th>\n",
              "      <th>preco_ativo</th>\n",
              "      <th>volatilidade</th>\n",
              "      <th>taxa_juros</th>\n",
              "      <th>black_scholes</th>\n",
              "      <th>delta_black_scholes</th>\n",
              "      <th>base</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-01-05</th>\n",
              "      <td>PETRM17</td>\n",
              "      <td>OPÇÕES DE VENDA</td>\n",
              "      <td>8.18</td>\n",
              "      <td>16.91</td>\n",
              "      <td>2015-01-19</td>\n",
              "      <td>0.039683</td>\n",
              "      <td>8.61</td>\n",
              "      <td>0.771953</td>\n",
              "      <td>0.1157</td>\n",
              "      <td>8.22</td>\n",
              "      <td>100</td>\n",
              "      <td>treino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-05</th>\n",
              "      <td>PETRM28</td>\n",
              "      <td>OPÇÕES DE VENDA</td>\n",
              "      <td>0.36</td>\n",
              "      <td>8.41</td>\n",
              "      <td>2015-01-19</td>\n",
              "      <td>0.039683</td>\n",
              "      <td>8.61</td>\n",
              "      <td>0.771953</td>\n",
              "      <td>0.1157</td>\n",
              "      <td>0.41</td>\n",
              "      <td>40</td>\n",
              "      <td>treino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-05</th>\n",
              "      <td>PETRM2</td>\n",
              "      <td>OPÇÕES DE VENDA</td>\n",
              "      <td>0.02</td>\n",
              "      <td>4.91</td>\n",
              "      <td>2015-01-19</td>\n",
              "      <td>0.039683</td>\n",
              "      <td>8.61</td>\n",
              "      <td>0.771953</td>\n",
              "      <td>0.1157</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>teste</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-05</th>\n",
              "      <td>PETRM23</td>\n",
              "      <td>OPÇÕES DE VENDA</td>\n",
              "      <td>0.79</td>\n",
              "      <td>9.21</td>\n",
              "      <td>2015-01-19</td>\n",
              "      <td>0.039683</td>\n",
              "      <td>8.61</td>\n",
              "      <td>0.771953</td>\n",
              "      <td>0.1157</td>\n",
              "      <td>0.87</td>\n",
              "      <td>63</td>\n",
              "      <td>treino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-05</th>\n",
              "      <td>PETRM25</td>\n",
              "      <td>OPÇÕES DE VENDA</td>\n",
              "      <td>1.13</td>\n",
              "      <td>9.61</td>\n",
              "      <td>2015-01-19</td>\n",
              "      <td>0.039683</td>\n",
              "      <td>8.61</td>\n",
              "      <td>0.771953</td>\n",
              "      <td>0.1157</td>\n",
              "      <td>1.16</td>\n",
              "      <td>73</td>\n",
              "      <td>treino</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             codigo          mercado  ...  delta_black_scholes    base\n",
              "2015-01-05  PETRM17  OPÇÕES DE VENDA  ...                  100  treino\n",
              "2015-01-05  PETRM28  OPÇÕES DE VENDA  ...                   40  treino\n",
              "2015-01-05   PETRM2  OPÇÕES DE VENDA  ...                    0   teste\n",
              "2015-01-05  PETRM23  OPÇÕES DE VENDA  ...                   63  treino\n",
              "2015-01-05  PETRM25  OPÇÕES DE VENDA  ...                   73  treino\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUk1bDlz5rSj"
      },
      "source": [
        "# Engenharia das variáveis (Feature Engineering)\n",
        "\n",
        "Essa sessão é composta da transformação dos dados para entrada na rede na rede neural. Portando, as variáveis são transformadas do seu valor original, seja para adequação dentro da rede neural ou para um melhor treinamento da rede, essas transformações são:\n",
        "\n",
        "- Variavéis númericas: preco_exercicio, preco_ativo, foram normalizadas antes da entrada na rede\n",
        "- Variavéis númericas: preco_opcao (alvo), volatilidade, taxa_juros e T não sofreram alterações\n",
        "- Variável categórica mercado sofreu one hot encoding\n",
        "\n",
        "A transformação dos dados é feita no mesmo momento que o modelo é treinado, isso é feito através de uma camada dentro do modelo, essa camada tem o nome de feature layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SPYLAtTPyox",
        "cellView": "form"
      },
      "source": [
        "#@title Pipeline de entrada dos dados\n",
        "def df_to_dataset(dataframe, base, shuffle=True, batch_size=22):\n",
        "\n",
        "    # Criar cópia do dataframe\n",
        "    dataframe = dataframe.copy()\n",
        "\n",
        "    # Filtrar a base\n",
        "    dataframe = dataframe[dataframe['base'] == base]\n",
        "\n",
        "    # Variavel alvo\n",
        "    labels = dataframe.pop('preco_opcao')\n",
        "\n",
        "    # Colunas do modelo\n",
        "    cols = ['mercado', 'preco_exercicio', 'preco_ativo', 'T', 'volatilidade', 'taxa_juros']\n",
        "\n",
        "    # Criar o td.data\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe[cols]), labels))\n",
        "\n",
        "    # Embaralhar os dados se necessário\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "\n",
        "    # Criar o batch de dados\n",
        "    ds = ds.batch(batch_size)\n",
        "\n",
        "    return ds\n",
        "\n",
        "# Divisão da base de treino e teste\n",
        "train_ds = df_to_dataset(data, base='treino')\n",
        "test_ds = df_to_dataset(data, shuffle=False, base='teste')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BHv1LRx6YDy",
        "cellView": "form"
      },
      "source": [
        "#@title Mapeamento das colunas\n",
        "feature_columns = []\n",
        "\n",
        "# Colunas númericas normalizadas\n",
        "for column in ['preco_exercicio', 'preco_ativo']:\n",
        "    \n",
        "    mean = data.loc[data['base'] == 'treino', column].mean()\n",
        "    stdev = data.loc[data['base'] == 'treino', column].std()\n",
        "\n",
        "    feature_columns.append(tf.feature_column.numeric_column(column, normalizer_fn = lambda x: (x - mean) / stdev))\n",
        "\n",
        "# Colunas númericas sem normalização\n",
        "for column in ['T', 'volatilidade', 'taxa_juros']:\n",
        "\n",
        "    feature_columns.append(tf.feature_column.numeric_column(column))\n",
        "\n",
        "# Colunas categóricas\n",
        "option = tf.feature_column.categorical_column_with_vocabulary_list('mercado', ['OPÇÕES DE COMPRA', 'OPÇÕES DE VENDA'])\n",
        "option_one_hot = tf.feature_column.indicator_column(option)\n",
        "feature_columns.append(option_one_hot)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6404E6Z6QIA",
        "cellView": "form"
      },
      "source": [
        "#@title Camada de transformação (feature layer)\n",
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns, name='Feature')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aQF2cGN5w6M"
      },
      "source": [
        "# Modelo\n",
        "\n",
        "O modelo de rede neural profunda a seguir, foi baseado nos estudos desenvolvidos por Hirsa, Karatas, & Oskoui. No trabalho são testadas diversas arquiteturas (camadas e elementos em cada camada), bem como função de atição de cada camada e também função de otimização.\n",
        "\n",
        "A conclusão do estudo mostra que os melhores resultados foram obtidos utilizando uma rede de 4 camadas com 120 neurônios cada uma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DKrtEWj_F25"
      },
      "source": [
        "#@title Model Subclassing\n",
        "class DNN_Model(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(DNN_Model, self).__init__()\n",
        "        self.feature = feature_layer\n",
        "        self.d1 = tf.keras.layers.Dense(120, activation='relu', name='Dense_1')\n",
        "        self.d2 = tf.keras.layers.Dense(120, activation='relu', name='Dense_2')\n",
        "        self.d3 = tf.keras.layers.Dense(120, activation='relu', name='Dense_3')\n",
        "        self.d4 = tf.keras.layers.Dense(120, activation='relu', name='Dense_4')\n",
        "        self.output_kayer = tf.keras.layers.Dense(1, name='output')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        h = self.feature(inputs)\n",
        "        h = self.d1(h)\n",
        "        h = self.d2(h)\n",
        "        h = self.d3(h)\n",
        "        h = self.d4(h)\n",
        "        return self.output_kayer(h)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = DNN_Model()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOzIUkPi4E1_",
        "outputId": "92b689eb-db67-4d09-e351-6d966617a0ee"
      },
      "source": [
        "#@title Inicialização do modelo\n",
        "# Para apresentar o sumário do modelo, primeiramente, é necessário inicializar os pesos e bias de cada camada,\n",
        "# isso é feito utilizando uma amostra dos dados\n",
        "element = next(iter(train_ds.take(1)))[0]\n",
        "model(element)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(22, 1), dtype=float32, numpy=\n",
              "array([[ 0.04783595],\n",
              "       [ 0.07835528],\n",
              "       [ 0.00552963],\n",
              "       [ 0.00041123],\n",
              "       [ 0.07175818],\n",
              "       [ 0.06814009],\n",
              "       [ 0.14946648],\n",
              "       [ 0.13198915],\n",
              "       [ 0.0051135 ],\n",
              "       [ 0.05440015],\n",
              "       [ 0.10923524],\n",
              "       [ 0.0741863 ],\n",
              "       [ 0.05338414],\n",
              "       [ 0.04139257],\n",
              "       [ 0.06089517],\n",
              "       [ 0.13722904],\n",
              "       [ 0.02693585],\n",
              "       [ 0.05808833],\n",
              "       [ 0.02142004],\n",
              "       [-0.00056502],\n",
              "       [ 0.07546006],\n",
              "       [ 0.04938966]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Wi2r88B4Wjg",
        "outputId": "e425a71c-a716-407a-bd85-a8c0c059c7d9"
      },
      "source": [
        "#@title Sumário do modelo\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"dnn__model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Feature (DenseFeatures)      multiple                  0         \n",
            "_________________________________________________________________\n",
            "Dense_1 (Dense)              multiple                  960       \n",
            "_________________________________________________________________\n",
            "Dense_2 (Dense)              multiple                  14520     \n",
            "_________________________________________________________________\n",
            "Dense_3 (Dense)              multiple                  14520     \n",
            "_________________________________________________________________\n",
            "Dense_4 (Dense)              multiple                  14520     \n",
            "_________________________________________________________________\n",
            "output (Dense)               multiple                  121       \n",
            "=================================================================\n",
            "Total params: 44,641\n",
            "Trainable params: 44,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeiiFv-kJRQZ"
      },
      "source": [
        "#@title Função de perda e otimizador\n",
        "loss_object = tf.keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mse\")\n",
        "optimizer = tf.keras.optimizers.Adam(0.001)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5gjLfDcJVBB"
      },
      "source": [
        "#@title Métricas\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_mae = tf.keras.metrics.MeanAbsoluteError(name='train_mae')\n",
        "train_mape = tf.keras.metrics.MeanAbsolutePercentageError(name='train_mape')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_mae = tf.keras.metrics.MeanAbsoluteError(name='test_mae')\n",
        "test_mape = tf.keras.metrics.MeanAbsolutePercentageError(name='test_mape')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcHPmrZDJZEN"
      },
      "source": [
        "#@title Aplicando gradiente\n",
        "@tf.function\n",
        "def train_step(data, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(data, training=True)\n",
        "        loss = loss_object(predictions, labels)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_mae(labels, predictions)\n",
        "    train_mape(labels, predictions)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n20De_RbJlBG"
      },
      "source": [
        "#@title Função de teste\n",
        "@tf.function\n",
        "def test_step(data, labels):\n",
        "  predictions = model(data, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_mae(labels, predictions)\n",
        "  test_mape(labels, predictions)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-f4q8-EJo4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db1e1f09-11f3-4e73-f94c-2678de12c14d"
      },
      "source": [
        "#@title Treinamento do modelo\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Re-inicia as métricas a cada época\n",
        "    train_loss.reset_states()\n",
        "    train_mae.reset_states()\n",
        "    train_mape.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_mae.reset_states()\n",
        "    test_mape.reset_states()\n",
        "\n",
        "    for data, labels in train_ds:\n",
        "        train_step(data, labels)\n",
        "\n",
        "    for test_data, test_labels in test_ds:\n",
        "        test_step(test_data, test_labels)\n",
        "\n",
        "    print(\n",
        "        f'Epoch {epoch + 1}, '\n",
        "        f'Loss: {train_loss.result():.4f}, '\n",
        "        f'MAE: {train_mae.result():.4f}, '\n",
        "        f'MAPE: {train_mape.result():.4f}, '\n",
        "        f'Test_Loss: {test_loss.result():.4f}, '\n",
        "        f'Test_MAE: {test_mae.result():.4f}, '\n",
        "        f'Test_MAPE: {test_mape.result():.4f}'\n",
        "        )"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.1194, MAE: 0.1829, MAPE: 101.0916, Test_Loss: 0.0793, Test_MAE: 0.1432, Test_MAPE: 47.8851\n",
            "Epoch 2, Loss: 0.0643, MAE: 0.1444, MAPE: 56.6683, Test_Loss: 0.0730, Test_MAE: 0.1517, Test_MAPE: 82.7700\n",
            "Epoch 3, Loss: 0.0595, MAE: 0.1359, MAPE: 49.4900, Test_Loss: 0.0604, Test_MAE: 0.1247, Test_MAPE: 53.2899\n",
            "Epoch 4, Loss: 0.0575, MAE: 0.1322, MAPE: 46.1591, Test_Loss: 0.0621, Test_MAE: 0.1363, Test_MAPE: 53.0687\n",
            "Epoch 5, Loss: 0.0562, MAE: 0.1292, MAPE: 44.7188, Test_Loss: 0.0604, Test_MAE: 0.1334, Test_MAPE: 62.3024\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}