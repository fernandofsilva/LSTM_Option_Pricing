{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_modelo_dnn_sequential.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Y7Dcl5z6KJkihBD6ewPwZkKS706zMOKz",
      "authorship_tag": "ABX9TyNA/2V0REsQ4IraoSrgoCuv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernandofsilva/LSTM_Option_Pricing/blob/main/notebooks/03_modelo_dnn_sequential.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ygLRzapGrpY"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kXVG3GRGiDn"
      },
      "source": [
        "#@title Carregando as bibliotecas base\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "\n",
        "seaborn.set_style('whitegrid')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4xb9NkUtG031",
        "outputId": "98b44861-2184-4756-8f28-6a89779f7724"
      },
      "source": [
        "#@title Carregando os dados\n",
        "data = pd.read_csv(f'/content/drive/My Drive/Mestrado/data/dados_treino_teste.csv.gz', compression='gzip', index_col=0)\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>codigo</th>\n",
              "      <th>mercado</th>\n",
              "      <th>preco_opcao</th>\n",
              "      <th>preco_exercicio</th>\n",
              "      <th>data_vencimento</th>\n",
              "      <th>T</th>\n",
              "      <th>preco_ativo</th>\n",
              "      <th>volatilidade</th>\n",
              "      <th>taxa_juros</th>\n",
              "      <th>black_scholes</th>\n",
              "      <th>delta_black_scholes</th>\n",
              "      <th>base</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-01-05</th>\n",
              "      <td>PETRM17</td>\n",
              "      <td>OPÇÕES DE VENDA</td>\n",
              "      <td>8.18</td>\n",
              "      <td>16.91</td>\n",
              "      <td>2015-01-19</td>\n",
              "      <td>0.039683</td>\n",
              "      <td>8.61</td>\n",
              "      <td>0.771953</td>\n",
              "      <td>0.1157</td>\n",
              "      <td>8.22</td>\n",
              "      <td>100</td>\n",
              "      <td>treino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-05</th>\n",
              "      <td>PETRM28</td>\n",
              "      <td>OPÇÕES DE VENDA</td>\n",
              "      <td>0.36</td>\n",
              "      <td>8.41</td>\n",
              "      <td>2015-01-19</td>\n",
              "      <td>0.039683</td>\n",
              "      <td>8.61</td>\n",
              "      <td>0.771953</td>\n",
              "      <td>0.1157</td>\n",
              "      <td>0.41</td>\n",
              "      <td>40</td>\n",
              "      <td>treino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-05</th>\n",
              "      <td>PETRM2</td>\n",
              "      <td>OPÇÕES DE VENDA</td>\n",
              "      <td>0.02</td>\n",
              "      <td>4.91</td>\n",
              "      <td>2015-01-19</td>\n",
              "      <td>0.039683</td>\n",
              "      <td>8.61</td>\n",
              "      <td>0.771953</td>\n",
              "      <td>0.1157</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>teste</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-05</th>\n",
              "      <td>PETRM23</td>\n",
              "      <td>OPÇÕES DE VENDA</td>\n",
              "      <td>0.79</td>\n",
              "      <td>9.21</td>\n",
              "      <td>2015-01-19</td>\n",
              "      <td>0.039683</td>\n",
              "      <td>8.61</td>\n",
              "      <td>0.771953</td>\n",
              "      <td>0.1157</td>\n",
              "      <td>0.87</td>\n",
              "      <td>63</td>\n",
              "      <td>treino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-05</th>\n",
              "      <td>PETRM25</td>\n",
              "      <td>OPÇÕES DE VENDA</td>\n",
              "      <td>1.13</td>\n",
              "      <td>9.61</td>\n",
              "      <td>2015-01-19</td>\n",
              "      <td>0.039683</td>\n",
              "      <td>8.61</td>\n",
              "      <td>0.771953</td>\n",
              "      <td>0.1157</td>\n",
              "      <td>1.16</td>\n",
              "      <td>73</td>\n",
              "      <td>treino</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             codigo          mercado  ...  delta_black_scholes    base\n",
              "2015-01-05  PETRM17  OPÇÕES DE VENDA  ...                  100  treino\n",
              "2015-01-05  PETRM28  OPÇÕES DE VENDA  ...                   40  treino\n",
              "2015-01-05   PETRM2  OPÇÕES DE VENDA  ...                    0   teste\n",
              "2015-01-05  PETRM23  OPÇÕES DE VENDA  ...                   63  treino\n",
              "2015-01-05  PETRM25  OPÇÕES DE VENDA  ...                   73  treino\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mje48ihnG2wD"
      },
      "source": [
        "# Engenharia das variáveis (Feature Engineering)\n",
        "\n",
        "Essa sessão é composta da transformação dos dados para entrada na rede na rede neural. Portando, as variáveis são transformadas do seu valor original, seja para adequação dentro da rede neural ou para um melhor treinamento da rede, essas transformações são:\n",
        "\n",
        "- Variavéis númericas: preco_exercicio, preco_ativo, foram normalizadas antes da entrada na rede\n",
        "- Variavéis númericas: preco_opcao (alvo), volatilidade, taxa_juros e T não sofreram alterações\n",
        "- Variável categórica mercado sofreu one hot encoding\n",
        "\n",
        "A transformação dos dados é feita no mesmo momento que o modelo é treinado, isso é feito através de uma camada dentro do modelo, essa camada tem o nome de feature layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mlmg1GsG409"
      },
      "source": [
        "#@title Pipeline de entrada dos dados\n",
        "def df_to_dataset(dataframe, base, shuffle=True, batch_size=22):\n",
        "\n",
        "    # Criar cópia do dataframe\n",
        "    dataframe = dataframe.copy()\n",
        "\n",
        "    # Filtrar a base\n",
        "    dataframe = dataframe[dataframe['base'] == base]\n",
        "\n",
        "    # Variavel alvo\n",
        "    labels = dataframe.pop('preco_opcao')\n",
        "\n",
        "    # Colunas do modelo\n",
        "    cols = ['mercado', 'preco_exercicio', 'preco_ativo', 'T', 'volatilidade', 'taxa_juros']\n",
        "\n",
        "    # Criar o td.data\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe[cols]), labels))\n",
        "\n",
        "    # Embaralhar os dados se necessário\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "\n",
        "    # Criar o batch de dados\n",
        "    ds = ds.batch(batch_size)\n",
        "\n",
        "    return ds\n",
        "\n",
        "# Divisão da base de treino e teste\n",
        "train_ds = df_to_dataset(data, base='treino')\n",
        "test_ds = df_to_dataset(data, shuffle=False, base='teste')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nJIv0n7G6tk"
      },
      "source": [
        "#@title Mapeamento das colunas\n",
        "feature_columns = []\n",
        "\n",
        "# Colunas númericas normalizadas\n",
        "for column in ['preco_exercicio', 'preco_ativo']:\n",
        "    \n",
        "    mean = data.loc[data['base'] == 'treino', column].mean()\n",
        "    stdev = data.loc[data['base'] == 'treino', column].std()\n",
        "\n",
        "    feature_columns.append(tf.feature_column.numeric_column(column, normalizer_fn = lambda x: (x - mean) / stdev))\n",
        "\n",
        "# Colunas númericas sem normalização\n",
        "for column in ['T', 'volatilidade', 'taxa_juros']:\n",
        "\n",
        "    feature_columns.append(tf.feature_column.numeric_column(column))\n",
        "\n",
        "# Colunas categóricas\n",
        "option = tf.feature_column.categorical_column_with_vocabulary_list('mercado', ['OPÇÕES DE COMPRA', 'OPÇÕES DE VENDA'])\n",
        "option_one_hot = tf.feature_column.indicator_column(option)\n",
        "feature_columns.append(option_one_hot)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3aRjMaMG8bP"
      },
      "source": [
        "#@title Camada de transformação (feature layer)\n",
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns, name='Feature')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hBWxmChG_GH"
      },
      "source": [
        "# Modelo\n",
        "\n",
        "O modelo de rede neural profunda a seguir, foi baseado nos estudos desenvolvidos por Hirsa, Karatas, & Oskoui. No trabalho são testadas diversas arquiteturas (camadas e elementos em cada camada), bem como função de ativão de cada camada e também função de otimização.\n",
        "\n",
        "A conclusão do estudo mostra que os melhores resultados foram obtidos utilizando uma rede de 4 camadas com 120 neurônios cada uma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvZ0416fG-Yv",
        "outputId": "30676d6f-801e-41a0-ddfa-2a8dcaef2b90"
      },
      "source": [
        "#@title Criar, compilar e treinar o modelo\n",
        "# Define Callback\n",
        "class mse_Callback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_loss')<0.075):\n",
        "      print(\"\\nReached Mean Squared Erro less than 0.075, it is cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "# Define de model\n",
        "model = tf.keras.Sequential([\n",
        "  feature_layer,\n",
        "  tf.keras.layers.Dense(120, activation='relu'),\n",
        "  tf.keras.layers.Dense(120, activation='relu'),\n",
        "  tf.keras.layers.Dense(120, activation='relu'),\n",
        "  tf.keras.layers.Dense(120, activation='elu'),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss='mse',\n",
        "    metrics=[tf.keras.metrics.MeanAbsoluteError(name=\"MAE\", dtype=None)]\n",
        ")\n",
        "\n",
        "# Instantiete callbacks\n",
        "callbacks = mse_Callback()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_ds, validation_data=test_ds, epochs=200, callbacks=[callbacks])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'mercado': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'preco_exercicio': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'preco_ativo': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'T': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'volatilidade': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'taxa_juros': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'mercado': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'preco_exercicio': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'preco_ativo': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'T': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'volatilidade': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'taxa_juros': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "7402/7416 [============================>.] - ETA: 0s - loss: 0.1094 - MAE: 0.1812WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'mercado': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'preco_exercicio': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'preco_ativo': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'T': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'volatilidade': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'taxa_juros': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "\n",
            "Reached Mean Squared Erro less than 0.075, it is cancelling training!\n",
            "7416/7416 [==============================] - 17s 2ms/step - loss: 0.1093 - MAE: 0.1812 - val_loss: 0.0704 - val_MAE: 0.1619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7qSKR06HF0Z"
      },
      "source": [
        "#@title Plot das Métricas do Modelo\n",
        "# Split variables\n",
        "train_loss = history.history['loss']\n",
        "test_loss = history.history['val_loss']\n",
        "train_mae = history.history['MAE']\n",
        "test_mae = history.history['val_MAE']\n",
        "train_mape = history.history['MAPE']\n",
        "test_mape = history.history['val_MAPE']\n",
        "epoch = range(len(test_mape))\n",
        "\n",
        "# Create two subplots\n",
        "fig, axs = plt.subplots(3, 1, figsize=(20, 8))\n",
        "axs[0].plot(epoch, train_loss, 'tab:blue', label='treino')\n",
        "axs[0].plot(epoch, test_loss, 'tab:red', label='teste')\n",
        "axs[0].set_title('Função de Perda')\n",
        "axs[0].set(ylabel='Perda')\n",
        "# axs[0].set_ylim([0, 1])\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(epoch, train_mae, 'tab:blue', label='treino')\n",
        "axs[1].plot(epoch, test_mae, 'tab:red', label='teste')\n",
        "axs[1].set_title('Erro Médio Absoluto')\n",
        "axs[1].set(ylabel='MAE')\n",
        "# axs[1].set_ylim([0, 2])\n",
        "axs[1].legend()\n",
        "\n",
        "axs[2].plot(epoch, train_mape, 'tab:blue', label='treino')\n",
        "axs[2].plot(epoch, test_mape, 'tab:red', label='teste')\n",
        "axs[2].set_title('Erro Médio Percentual Absoluto')\n",
        "axs[2].set(ylabel='MAPE')\n",
        "# axs[2].set_ylim([0, 2])\n",
        "axs[2].legend()\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='Épocas')\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUxeiDTQHLSQ"
      },
      "source": [
        "# Gráficos das opções\n",
        "\n",
        "Para comparação foram escolhidas aleatóriamente 10 opções da base de teste."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUAPYUS0HNjM"
      },
      "source": [
        "#@title Função de comparação\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def predict(model, data, options, expire):\n",
        "\n",
        "    # Select options\n",
        "    df = data[(data['option'] == options) & (data['expire'] == expire)]\n",
        "\n",
        "    # Convert to dataset\n",
        "    ds = df_to_dataset(df, shuffle=False)\n",
        "\n",
        "    # Predict values\n",
        "    pred = model.predict(ds)\n",
        "\n",
        "    rmse_bs = np.sqrt(mean_squared_error(df['value'],df['bs']))\n",
        "    rmse_dnn = np.sqrt(mean_squared_error(df['value'], pred))\n",
        "    if rmse_dnn < rmse_bs:\n",
        "        result = 'Rede Neural'\n",
        "    else:\n",
        "        result = 'Black-Scholes'\n",
        "\n",
        "    fig, axs = plt.subplots(figsize=(20, 4))\n",
        "    axs.plot(df.index, pred, 'tab:blue', label='DNN')\n",
        "    axs.plot(df.index, df['bs'], 'tab:green', label='BS')\n",
        "    axs.plot(df.index, df['value'], 'tab:red', label=options)\n",
        "    axs.set_title(f'{options} - Black-Scholes:{rmse_bs:.4f}, DNN:{rmse_dnn:.4f}, Melhor modelo {result}')\n",
        "    axs.set(ylabel='Valor R$')\n",
        "    axs.set(xlabel='data')\n",
        "    axs.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-KZm2l7HRO4"
      },
      "source": [
        "#@title \n",
        "for option_type in ['call', 'put']:\n",
        "    \n",
        "    options = test.loc[test['option_type'] == option_type, ['option', 'expire']].drop_duplicates()\n",
        "\n",
        "    for _ in range(5):\n",
        "\n",
        "        rand = np.random.randint(options.shape[0])\n",
        "\n",
        "        predict(\n",
        "            model,\n",
        "            data,\n",
        "            options.iloc[rand, 0],\n",
        "            options.iloc[rand, 1]\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT-x-RIbK-Hc"
      },
      "source": [
        "# Reference\n",
        "\n",
        "Hirsa, A., Karatas, T., & Oskoui, A. (2019). Supervised deep neural networks (DNNS) for pricing/calibration of vanilla/exotic options under various different processes."
      ]
    }
  ]
}